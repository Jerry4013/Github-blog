---
title:  "AI(2) -- Intelligent Agents"
tags: AI
---

## Agents and Environments

An agent is anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators.

An agent's percept sequence is the complete history of everything the agent has ever perceived.

Mathematically speaking, an agent's behavior is described by the agent function that maps any given percept sequence to an action.

Internally, implemented by an agent program.

Agent function: abstract mathematical description; Agent program: concrete implementation, running within some physical system.

## Good Behavior: The Concept of Rationality

A rational agent is one that does the right thing--conceptually speaking, every entry in the table for the agent function is filled out correctly.

This notion of desirability is captured by a performance measure that evaluates any given sequence of environment states.

As a general rule, it is better to design performance measures according to what one actually wants in the environment, rather than according to how one thinks the agent should behave.

### Rationality

What is rational at any time depends on four things:

* The performance measure that defines the criterion of success.
* The agent's prior knowledge of the environment.
* The actions that the agent can perform.
* The agent's percept sequence to date.

### Omniscience, learning, and autonomy

Rationality is not the same as perfection. Rationality maximizes expected performance, while perfection maximizes actual performance.

Doing actions in order to modify future percepts--sometimes called information gathering--is an important part of rationality.

Not only to gather information but also to learn as much as possible from what it perceives.

To the extent that an agent relies on the prior knowledge of its designer rather than on its own percepts, we say that the agent lacks autonomy. 

## The Nature of Environments

### Specifying the task environment

Task environment: specifying the performance measure, the environment, and the agent's actuators and sensors. We call this the PEAS (Performance, Environment, Actuators, Sensors) description. 

### Properties of task environments

* Fully observable vs. partially observable
* Single agent vs. multiagent
* Deterministic vs. stockastic
* Episodic vs. sequential
* Static vs. dynamic
* Discrete vs. continuous
* Known vs. unknown

## The Structure of Agents

agent = architecture + program

### Agent programs

* Simple reflex agents
* Model-based reflex agents
* Goal-based agents
* Utility-based agents
* Learning agents









